{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from consts import MY_OPENAI_API_KEY as API_KEY\n",
    "CACHE_DIR = '../cache/'\n",
    "FIRST_PROMPT = \"You are a helpful assistant designed to output JSON. The client provides you with text containing sales announcements, and you need to create JSON for these announcements to input into the database. The JSON should be a list of dictionaries, where each announcement is a separate dictionary. Each dictionary must include the fields: name, price, description (if available, otherwise null), place (information about the seller's location, the same for all products if provided, otherwise null), count (if multiple items are being sold at once, otherwise null), and others (a dictionary with other useful information about the product).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import typing as tp\n",
    "from IPython.display import display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = openai.OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CACHE_DIR + 'prompt_test_df.pkl', 'rb') as f:\n",
    "  df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAICache:\n",
    "  def __init__(self, client):\n",
    "    self.client = client\n",
    "    self.storage = {}\n",
    "  \n",
    "  def request(self, prompt, text):\n",
    "    if prompt not in self.storage:\n",
    "      self.storage[prompt] = {}\n",
    "    if text not in self.storage[prompt]:\n",
    "      response = self.client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": prompt},\n",
    "          {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "      )\n",
    "      self.storage[prompt][text] = response\n",
    "    return self.storage[prompt][text]\n",
    "\n",
    "class Prompt:\n",
    "  def __init__(self, prompt:str, openai_cache:OpenAICache, fake_mode=False):\n",
    "    self.prompt = prompt\n",
    "    self.results = {}\n",
    "    self.responses = []\n",
    "    self.openai = openai_cache\n",
    "    self.fake_mode = fake_mode\n",
    "  \n",
    "  def make_requests(self, df:pd.DataFrame, rewrite=False):\n",
    "    for id in df.index:\n",
    "      if id not in self.results or rewrite:\n",
    "        response = self.openai.request(self.prompt, df.iloc[id]['text'])\n",
    "        if not self.fake_mode:\n",
    "          self.results[id] = json.loads(response.choices[0].message.content)\n",
    "        else:\n",
    "          self.results[id] = json.loads(response)\n",
    "\n",
    "def make_flat_dict(obj):\n",
    "  if isinstance(obj, list):\n",
    "    obj = {str(i):obj[i] for i in range(len(obj))}\n",
    "  if not isinstance(obj, dict):\n",
    "    return obj\n",
    "  new_obj = {}\n",
    "  for key in obj.keys():\n",
    "    val = make_flat_dict(obj[key])\n",
    "    if isinstance(val, dict):\n",
    "      for subkey in val.keys():\n",
    "        new_obj[str(key) + '_' + subkey] = val[subkey]\n",
    "    else:\n",
    "      new_obj[str(key)] = val\n",
    "  return new_obj\n",
    "\n",
    "class PromptManager:\n",
    "  def __init__(self, df, openai_cache):\n",
    "    self.df = df\n",
    "    self.openai = openai_cache\n",
    "    self.prompts = {}\n",
    "    self.baseline_name = None\n",
    "    self.fake_mode = False\n",
    "\n",
    "  def add(self, name, prompt:str):\n",
    "    if name not in self.prompts:\n",
    "      self.prompts[name] = Prompt(prompt, openai_cache=self.openai, fake_mode=self.fake_mode)\n",
    "\n",
    "  def make_requests(self, name):\n",
    "    self.prompts[name].make_requests(self.df)\n",
    "  \n",
    "  def compare(self, name1, name2):\n",
    "    res1 = make_flat_dict(self.prompts[name1].results)\n",
    "    res2 = make_flat_dict(self.prompts[name2].results)\n",
    "\n",
    "    diff = []\n",
    "    for key in set(res1.keys())|set(res2.keys()):\n",
    "      val1 = res1[key] if key in res1 else '<no key>'\n",
    "      val2 = res2[key] if key in res2 else '<no key>'\n",
    "      if val1 != val2:\n",
    "        col1 = name1 + (' (baseline)' if name1 == self.baseline_name else '')\n",
    "        diff.append({'field':key, col1:val1, name2:val2})\n",
    "\n",
    "    display(pd.DataFrame(diff))   \n",
    "    return diff\n",
    "\n",
    "  def compare_to_baseline(self, name):\n",
    "    return self.compare(self.baseline_name, name)\n",
    "\n",
    "  def make_all(self, name, prompt):\n",
    "    self.add(name, prompt)\n",
    "    self.make_requests(name)\n",
    "    if self.baseline_name is not None:\n",
    "      self.compare_to_baseline(name)\n",
    "    else:\n",
    "      self.baseline_name = name\n",
    "\n",
    "  def set_baseline(self, name):\n",
    "    self.baseline_name = name\n",
    "\n",
    "  def print_prompt(self, name):\n",
    "    print(self.prompts[name].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "REQ = 'Всем доброго дня! \\n\\nПродаю туфли, метро Новокосино. \\n\\n1. Бежевые лакированные туфли, размер 35. Абсолютно новые. — 1000р. \\n2. Синие туфли, размер 36. Абсолютно новые. — 1000р. \\n3. Чёрные лакированные туфли из натуральной кожи марки Elmonte. Размер 36. Носились пару раз, в отличном состоянии. Стоят новые набойки и профилактика. — 1000р. \\n4. Чёрные туфли под замшу. Размер 36. Носились недолго и аккуратно, в хорошем состоянии. — 500р.'\n",
    "FAKE_PROMPT = 'lol'\n",
    "class FakeCache(OpenAICache):\n",
    "  def __init__(self):\n",
    "    self.storage = {\n",
    "      FIRST_PROMPT: {\n",
    "        REQ: \"\"\"[\n",
    "          {\n",
    "              \"name\": \"Бежевые лакированные туфли\",\n",
    "              \"price\": 1000,\n",
    "              \"description\": \"Абсолютно новые\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 35}\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Синие туфли\",\n",
    "              \"price\": 1000,\n",
    "              \"description\": \"Абсолютно новые\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 36}\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Чёрные лакированные туфли из натуральной кожи марки Elmonte\",\n",
    "              \"price\": 1000,\n",
    "              \"description\": \"Носились пару раз, в отличном состоянии. Стоят новые набойки и профилактика.\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 36}\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Чёрные туфли под замшу\",\n",
    "              \"price\": 500,\n",
    "              \"description\": \"Носились недолго и аккуратно, в хорошем состоянии.\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 36}\n",
    "          }\n",
    "        ]\"\"\"\n",
    "      },\n",
    "      FAKE_PROMPT: {\n",
    "        REQ: \"\"\"[\n",
    "          {\n",
    "              \"name\": \"Бежевые\",\n",
    "              \"price\": 1000,\n",
    "              \"description\": \"Абсолютно новые\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 35}\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Синие туфли\",\n",
    "              \"price\": 1000,\n",
    "              \"description\": \"Абсолютно новые\",\n",
    "              \"place\": \"метро\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 36}\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Чёрные лакированные туфли из натуральной кожи марки Elmonte\",\n",
    "              \"price\": 1000,\n",
    "              \"description\": \"Носились пару раз, в отличном состоянии. Стоят новые набойки и профилактика.\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 36}\n",
    "          },\n",
    "          {\n",
    "              \"name\": \"Чёрные туфли под замшу\",\n",
    "              \"price\": 400,\n",
    "              \"description\": \"Носились недолго и аккуратно, в хорошем состоянии.\",\n",
    "              \"place\": \"метро Новокосино\",\n",
    "              \"count\": null,\n",
    "              \"others\": {\"Размер\": 36}\n",
    "          }\n",
    "        ]\"\"\"\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FakeCache()\n",
    "fpm = PromptManager(pd.DataFrame([{'text':REQ}]), fc)\n",
    "fpm.fake_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpm.make_all('req1', FIRST_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>req1 (baseline)</th>\n",
       "      <th>req2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_3_price</td>\n",
       "      <td>500</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0_name</td>\n",
       "      <td>Бежевые лакированные туфли</td>\n",
       "      <td>Бежевые</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_1_place</td>\n",
       "      <td>метро Новокосино</td>\n",
       "      <td>метро</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       field             req1 (baseline)     req2\n",
       "0  0_3_price                         500      400\n",
       "1   0_0_name  Бежевые лакированные туфли  Бежевые\n",
       "2  0_1_place            метро Новокосино    метро"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpm.make_all('req2', FAKE_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from consts import LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
