{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "# import json\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9603\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>json</th>\n",
       "      <th>n_bundle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! –Ω–æ–≤–∞—è. —Ö–ª–æ–ø–∫–æ–≤–∞—è —Ä—É–±–∞—à–∫–∞ –æ–≤–µ—Ä—Å–∞–π–∑ —Å –ø—Ä–∏—è—Ç–Ω–æ–π...</td>\n",
       "      <td>[{'Title': '—Ö–ª–æ–ø–∫–æ–≤–∞—è —Ä—É–±–∞—à–∫–∞ –æ–≤–µ—Ä—Å–∞–π–∑', 'Pric...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!! –ü–û–ú–ò–î–û–†–ö–ò !!! –≤ 3–ª –ë–∞–Ω–∫–µ.... –ø–æ 250 —Ä—É–±. –ö...</td>\n",
       "      <td>[{'Title': '–ò–∫—Ä–∞ –ö–†–ê–°–ù–ê–Ø 140 –≥—Ä. –±–∞–Ω–∫–∞', 'Pric...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"–∫–æ–Ω—Ñ–µ—Ç–Ω—ã–π –º—è—á–∏–∫\" üç¨üèÄ —Ü–µ–Ω–∞ ‚Ç¨7üòª –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –¥–æ—Å—Ç–∞...</td>\n",
       "      <td>[{'Title': '–∫–æ–Ω—Ñ–µ—Ç–Ω—ã–π –º—è—á–∏–∫', 'Price': '7', 'C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># –¢–†–ò–ö–û –†–∞—Å–ø—Ä–æ–¥–∞–∂–∞ –±–µ–∑ –≤—ã–±–æ—Ä–∞–ú–û–î–ï–õ–¨ –¢–ö–ê–ù–¨ –¢–†–ò–ö...</td>\n",
       "      <td>[{'Title': '–¢—Ä–∏–∫–æ, –¥–≤—É—Ö –Ω–∏—Ç–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–ø–µ—Ä',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># –¢–†–ò–ö–û –†–∞—Å–ø—Ä–æ–¥–∞–∂–∞ –±–µ–∑ –≤—ã–±–æ—Ä–∞–ú–û–î–ï–õ–¨ –¢–ö–ê–ù–¨ –¢–†–ò–ö...</td>\n",
       "      <td>[{'Title': '–°—É–ø–µ—Ä–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∏–∫–æ—Ç–∞–∂ –∏–∑ –¥–≤—É—Ö...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  ! –Ω–æ–≤–∞—è. —Ö–ª–æ–ø–∫–æ–≤–∞—è —Ä—É–±–∞—à–∫–∞ –æ–≤–µ—Ä—Å–∞–π–∑ —Å –ø—Ä–∏—è—Ç–Ω–æ–π...   \n",
       "1  !!! –ü–û–ú–ò–î–û–†–ö–ò !!! –≤ 3–ª –ë–∞–Ω–∫–µ.... –ø–æ 250 —Ä—É–±. –ö...   \n",
       "2  \"–∫–æ–Ω—Ñ–µ—Ç–Ω—ã–π –º—è—á–∏–∫\" üç¨üèÄ —Ü–µ–Ω–∞ ‚Ç¨7üòª –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –¥–æ—Å—Ç–∞...   \n",
       "3  # –¢–†–ò–ö–û –†–∞—Å–ø—Ä–æ–¥–∞–∂–∞ –±–µ–∑ –≤—ã–±–æ—Ä–∞–ú–û–î–ï–õ–¨ –¢–ö–ê–ù–¨ –¢–†–ò–ö...   \n",
       "4  # –¢–†–ò–ö–û –†–∞—Å–ø—Ä–æ–¥–∞–∂–∞ –±–µ–∑ –≤—ã–±–æ—Ä–∞–ú–û–î–ï–õ–¨ –¢–ö–ê–ù–¨ –¢–†–ò–ö...   \n",
       "\n",
       "                                                json  n_bundle  \n",
       "0  [{'Title': '—Ö–ª–æ–ø–∫–æ–≤–∞—è —Ä—É–±–∞—à–∫–∞ –æ–≤–µ—Ä—Å–∞–π–∑', 'Pric...         1  \n",
       "1  [{'Title': '–ò–∫—Ä–∞ –ö–†–ê–°–ù–ê–Ø 140 –≥—Ä. –±–∞–Ω–∫–∞', 'Pric...         3  \n",
       "2  [{'Title': '–∫–æ–Ω—Ñ–µ—Ç–Ω—ã–π –º—è—á–∏–∫', 'Price': '7', 'C...         1  \n",
       "3  [{'Title': '–¢—Ä–∏–∫–æ, –¥–≤—É—Ö –Ω–∏—Ç–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–ø–µ—Ä',...         1  \n",
       "4  [{'Title': '–°—É–ø–µ—Ä–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∏–∫–æ—Ç–∞–∂ –∏–∑ –¥–≤—É—Ö...         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../labeled_15k.csv')\n",
    "df = df[df.Label_gpt == 'valid']\n",
    "df = df[['Text', 'Title', 'Price', 'Currency', 'Count']].reset_index(drop=True)\n",
    "df['json'] = pd.Series([[{'Title': row.Title, 'Price': row.Price, 'Currency': row.Currency, 'Count': row.Count}] for row in df.itertuples()])\n",
    "text_df = df[['Text', 'json']].groupby('Text').sum().reset_index()\n",
    "text_df['n_bundle'] = text_df.json.apply(len)\n",
    "\n",
    "single_bundle_mask = text_df.n_bundle == 1\n",
    "np.random.seed(42)\n",
    "test_set_index = np.random.choice(np.where(single_bundle_mask)[0], size=300, replace=False)\n",
    "test_mask = np.zeros(single_bundle_mask.shape, dtype=bool)\n",
    "test_mask[test_set_index] = True\n",
    "\n",
    "text_df, text_df_test = text_df[~test_mask], text_df[test_mask]\n",
    "\n",
    "# text_df, text_df_test = train_test_split(text_df, random_state=42, test_size=0.1)\n",
    "print(len(text_df))\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruT5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai-forever/ruT5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens([\"<BOB>\", \"<EOB>\", \"<BOT>\", \"<EOT>\", \"<BOP>\", \"<EOP>\", \"<BOC1>\", \"<EOC1>\", \"<BOC2>\", \"<EOC2>\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "def process_json(json):\n",
    "  return ''.join([f\"<BOB><BOT>{d['Title']}<EOT><BOP>{d['Price']}<EOP><BOC1>{d['Count']}<EOC1><BOC2>{d['Currency']}<EOC2><EOB>\" for d in json])\n",
    "\n",
    "def unprocess_json(s):\n",
    "  json = []\n",
    "  for t in re.findall(r'<BOB>(.*?)<EOB>', s):\n",
    "    try:\n",
    "      json.append({\n",
    "        'Title': re.findall(r'<BOT>(.*?)<EOT>', t)[0],\n",
    "        'Price': re.findall(r'<BOP>(.*?)<EOP>', t)[0],\n",
    "        'Count': re.findall(r'<BOC1>(.*?)<EOC1>', t)[0],\n",
    "        'Currency': re.findall(r'<BOC2>(.*?)<EOC2>', t)[0]\n",
    "      })\n",
    "    except Exception as e:\n",
    "      print(t)\n",
    "      raise e\n",
    "  return json\n",
    "assert text_df.loc[text_df.index[0], 'json'] == unprocess_json(process_json(text_df.loc[text_df.index[0], 'json']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 9122\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 481\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ads_test_dataset = Dataset.from_pandas(text_df_test[[\"Text\", \"json\"]]).flatten()\n",
    "\n",
    "ads_dataset = Dataset.from_pandas(text_df[[\"Text\", \"json\"]])\n",
    "ads_dataset = ads_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "ads_dataset = ads_dataset.flatten()\n",
    "ads_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e315ebd3604095bec81e93fde9090d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9122 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c779e3ea0ff64437acf319f55ab5e3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/481 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [text for text in examples[\"Text\"]]\n",
    "    # targets = ['' for bundles in examples[\"json\"]]\n",
    "    targets = [process_json(bundles) for bundles in examples[\"json\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "ads = ads_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ads_dataset[\"train\"].column_names\n",
    ")\n",
    "ads = ads.flatten()\n",
    "\n",
    "# ads_test = ads_test_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     num_proc=4,\n",
    "#     remove_columns=ads_test_dataset.column_names\n",
    "# )\n",
    "# ads_test = ads_test.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "class Evaluator:\n",
    "  def __init__(self, df, use_cache=False, batch_size=16):\n",
    "    self.batch_size=batch_size\n",
    "    self.df = df\n",
    "    self.failed_generations = 0\n",
    "    self.use_cache = use_cache\n",
    "    if use_cache:\n",
    "      self.cache = {}\n",
    "\n",
    "  def generate_text(self, input_text, device='cuda'):\n",
    "    if self.use_cache and input_text in self.cache:\n",
    "      return self.cache[input_text]\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    # model.eval()\n",
    "    # input_ids = torch.IntTensor([input_ids['input_ids']]).to(device)\n",
    "    with torch.no_grad():\n",
    "      outputs = model.generate(input_ids, max_length=128, early_stopping=True)\n",
    "      decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "      try:\n",
    "        json = unprocess_json(decoded_output)\n",
    "      except:\n",
    "        json = []\n",
    "        # self.failed_generations += 1\n",
    "      # generated_ids = model.generate(input_ids, max_length=512)\n",
    "    if self.use_cache:\n",
    "      self.cache[input_text] = json\n",
    "    return json\n",
    "\n",
    "  def generate_text_batch(self, input_texts, device='cuda'):\n",
    "    if not isinstance(input_texts, list):\n",
    "        raise ValueError(\"input_texts should be a list of strings\")\n",
    "    batch_size = len(input_texts)\n",
    "    input_ids = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).input_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids, max_length=128, early_stopping=True)\n",
    "        decoded_outputs = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        results = []\n",
    "        for decoded_output in decoded_outputs:\n",
    "            try:\n",
    "                json_output = unprocess_json(decoded_output)\n",
    "            except Exception as e:\n",
    "                json_output = []\n",
    "                # self.failed_generations += 1 if you want to track failed generations\n",
    "            results.append(json_output)\n",
    "            if self.use_cache:\n",
    "                for input_text, result in zip(input_texts, results):\n",
    "                    self.cache[input_text] = result\n",
    "\n",
    "    return results\n",
    "  \n",
    "  def generate_samples(self, ids=None, count=None):\n",
    "    if count is not None:\n",
    "      ids = self.df.index[:count]\n",
    "    if ids is None:\n",
    "      ids = self.df.index\n",
    "\n",
    "    results = {}\n",
    "    for i in ids:\n",
    "      input_text = self.df.loc[i, 'Text']\n",
    "      pred = self.generate_text(input_text)\n",
    "      if len(pred) == 0 or 'Title' not in pred[0]:\n",
    "        self.failed_generations += 1\n",
    "        results[i] = []\n",
    "      else:\n",
    "        results[i] = pred\n",
    "    return results\n",
    "  \n",
    "  def generate_samples_batched(self, ids=None, count=None, batch_size=8):\n",
    "    if count is not None:\n",
    "        ids = self.df.index[:count]\n",
    "    if ids is None:\n",
    "        ids = self.df.index\n",
    "\n",
    "    results = {}\n",
    "    all_texts = [self.df.loc[i, 'Text'] for i in ids]\n",
    "    all_ids = list(ids)\n",
    "    \n",
    "    for start in range(0, len(all_texts), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_texts = all_texts[start:end]\n",
    "        batch_ids = all_ids[start:end]\n",
    "        \n",
    "        predictions = self.generate_text_batch(batch_texts)\n",
    "        \n",
    "        for i, pred in zip(batch_ids, predictions):\n",
    "            if len(pred) == 0 or 'Title' not in pred[0]:\n",
    "                self.failed_generations += 1\n",
    "                results[i] = []\n",
    "            else:\n",
    "                results[i] = pred\n",
    "                \n",
    "    return results\n",
    "  \n",
    "  def calc_bleu(self):\n",
    "    refs = []\n",
    "    predictions = []\n",
    "    full_predictions = self.generate_samples()\n",
    "    for i, pred in full_predictions:\n",
    "      if len(pred) == 1 and 'Title' in pred[0]:\n",
    "        refs.append([self.df.loc[i, 'Title']])\n",
    "        predictions.append(pred[0]['Title'])\n",
    "    bleu_value = bleu_metric.compute(predictions=predictions, references=refs)\n",
    "    return {'bleu': bleu_value, 'failed_ratio': 1 - len(predictions) / len(self.df)}\n",
    "  \n",
    "  def calc_bleu_batched(self, batch_size=8):\n",
    "    refs = []\n",
    "    predictions = []\n",
    "    full_predictions = self.generate_samples_batched(batch_size=batch_size)\n",
    "    \n",
    "    for i, pred in full_predictions.items():\n",
    "        if len(pred) == 1 and 'Title' in pred[0]:\n",
    "            refs.append([self.df.loc[i, 'json'][0]['Title']])\n",
    "            predictions.append(pred[0]['Title'])\n",
    "    \n",
    "    if len(refs) != 0:\n",
    "      bleu_value = bleu_metric.compute(predictions=predictions, references=refs)['score']\n",
    "    else:\n",
    "      bleu_value = np.nan\n",
    "\n",
    "    return {'bleu': bleu_value, 'failed_ratio': 1 - len(predictions) / len(self.df)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class MetricComputer:\n",
    "  def __init__(self):\n",
    "    self.generations = []\n",
    "\n",
    "  def __call__(self, eval_preds):\n",
    "    ev = Evaluator(text_df_test)\n",
    "    stats = ev.calc_bleu_batched()\n",
    "    self.generations.append(ev.generate_samples_batched(count=20))\n",
    "    # clear_output()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 7\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ruT5-large\",\n",
    "    # overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=n_epochs,\n",
    "    # predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    group_by_length=False,\n",
    "    warmup_steps=3,\n",
    ")\n",
    "\n",
    "mc = MetricComputer()\n",
    "empty_dataset = Dataset.from_dict({\"Text\": [], \"json\": []})\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ads[\"train\"],\n",
    "    eval_dataset=ads[\"test\"],\n",
    "    # eval_dataset=empty_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=mc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3997' max='3997' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3997/3997 58:13, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Failed Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.470256</td>\n",
       "      <td>35.631757</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.417016</td>\n",
       "      <td>28.207157</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>27.745244</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.390581</td>\n",
       "      <td>30.747078</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>0.380656</td>\n",
       "      <td>33.978940</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>0.382794</td>\n",
       "      <td>30.384596</td>\n",
       "      <td>0.493333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.390927</td>\n",
       "      <td>28.965381</td>\n",
       "      <td>0.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.388672</td>\n",
       "      <td>24.471471</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.382368</td>\n",
       "      <td>23.794168</td>\n",
       "      <td>0.286667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.389495</td>\n",
       "      <td>25.344990</td>\n",
       "      <td>0.043333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.384726</td>\n",
       "      <td>26.408678</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.386142</td>\n",
       "      <td>24.767053</td>\n",
       "      <td>0.076667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.387262</td>\n",
       "      <td>24.768845</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOT> –∫–Ω–∏–≥–∞ Pro Core and EUR<EOC2>\n",
      "<BOT> –Ω–∞–±–æ—Ä –∏–∑ 5<EOC1><BOC2> RUB<EOC2>\n",
      "<BOT> –∫—Ä–æ—Å—Å–æ–≤–∫–∏<EOT><BOP> 1<EOC1><BOC2> GEL<EOC2>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3997, training_loss=0.3616401284880897, metrics={'train_runtime': 3494.9365, 'train_samples_per_second': 18.27, 'train_steps_per_second': 1.144, 'total_flos': 3.3469863638016e+16, 'train_loss': 0.3616401284880897, 'epoch': 7.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{56: [{'Title': ' Starship Samurai + Starship Shattered Alliances',\n",
       "   'Price': ' 10000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 125: [{'Title': ' –°–ø—è—â–∏–µ –±–æ–≥–∏ (–ø–æ–ª–Ω—ã–π –ø—Ä–µ–¥–∑–∞–∫–∞–∑ –∫—Ä–æ–º–µ –º–æ–Ω–µ—Ç + –æ—Ä–≥–∏)',\n",
       "   'Price': ' 9000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'},\n",
       "  {'Title': ' –ë–∞–∑–∞ + –ü—Ä–∏–ª–∏–≤—ã –≤ —Ä—É–∏–Ω–∞—Ö + –ü–æ–¥–∑–µ–º–µ–ª—å—è + –ø—Ä–æ–º–æ-–∫–∞—Ä—Ç—ã+ –º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏–π –∫–æ—Ä–∞–±–ª—å + –ø–ª–µ–π–º–∞—Ç + –æ—Ä–≥–∏ –æ—Ç meeplehouse',\n",
       "   'Price': ' 9000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 257: [{'Title': ' –ü–ª–µ–π–º–∞—Ç –∏ –Ω–∞–±–æ—Ä –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π',\n",
       "   'Price': ' 31000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 335: [{'Title': ' —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π —á–∞–π–Ω–∏–∫',\n",
       "   'Price': ' 90',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 347: [{'Title': ' Bluetooth-–≥–∞—Ä–Ω–∏—Ç—É—Ä–∞ Baofeng (Kenwood) —Å –º–æ–¥—É–ª–µ–º –ø–µ—Ä–µ–¥–∞—á–∏ –¥–ª—è —Ä–∞—Ü–∏–∏ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π',\n",
       "   'Price': ' 35',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' GEL'}],\n",
       " 476: [{'Title': ' –≤–∫—É—Å–Ω—è—à–∫–∏ –¥–ª—è —Å–æ–±–∞–∫',\n",
       "   'Price': ' 1500',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 723: [{'Title': ' –Ω–∞–±–æ—Ä –∏–∑ 14 –ø—Ä–µ–¥–º–µ—Ç–æ–≤',\n",
       "   'Price': ' 1100',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' USD'}],\n",
       " 796: [{'Title': ' Moonlight outdoor/indoor –Ω–∞–ø–æ–ª—å–Ω–æ-–ø–æ—Ç–æ–ª–æ—á–Ω—ã–π —à–∞—Ä-—Å–≤–µ—Ç–∏–ª—å–Ω–∏–∫ –æ—Ç One Light —Å –∞–∫—Å–µ—Å—Å—É–∞—Ä–∞–º–∏',\n",
       "   'Price': ' 80',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 814: [{'Title': ' 5 –±–æ–ª—å—à–∏—Ö –±–∞–Ω–æ–∫ 0.5–º–ª',\n",
       "   'Price': ' 3',\n",
       "   'Count': ' 5',\n",
       "   'Currency': ' EUR'}],\n",
       " 826: [{'Title': ' –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫—É—Ö–Ω–∏',\n",
       "   'Price': ' 5',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 839: [{'Title': ' —à–∞–º–ø—É—Ä—ã',\n",
       "   'Price': ' 7',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 895: [{'Title': ' —à–ª–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏',\n",
       "   'Price': ' 11000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 899: [{'Title': ' –ö–∞—Å—Å–µ—Ç –ù–µ—Ç—É',\n",
       "   'Price': ' 1000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 900: [{'Title': ' Puma suede',\n",
       "   'Price': ' 4600',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 977: [{'Title': ' apple watch stanless gold 4/44',\n",
       "   'Price': ' 550',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' GEL'}],\n",
       " 1037: [{'Title': ' ddr3 and hard drive',\n",
       "   'Price': ' 30',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' EUR'}],\n",
       " 1041: [{'Title': ' diablo 4 –¥–ª—è ps5',\n",
       "   'Price': ' 100',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' GEL'}],\n",
       " 1049: [{'Title': ' Dodge Journey 2009 2.0 CRD SXT –∞–≤—Ç–æ–º–∞—Ç, –¥–∏–∑–µ–ª—å, 7 –º–µ—Å—Ç, –ø—Ä–æ–±–µ–≥ 79800 –º–∏–ª—å',\n",
       "   'Price': ' 7000',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' RUB'}],\n",
       " 1056: [{'Title': ' evga rtx 3070ti xc3',\n",
       "   'Price': ' 930',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' GEL'}],\n",
       " 1072: [{'Title': ' god of war: ragnarok (ps4)',\n",
       "   'Price': ' 100',\n",
       "   'Count': ' 1',\n",
       "   'Currency': ' GEL'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.generations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = \"ruT5-large-too-good-try-3\"\n",
    "# model.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
