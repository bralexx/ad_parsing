{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from evaluator import Evaluator\n",
    "\n",
    "from json_format import SepTokenJSONProcessor\n",
    "\n",
    "json_proc = SepTokenJSONProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/FRED-T5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai-forever/FRED-T5-large\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained('fredT5-large-checkpoints/checkpoint-000')\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('fredT5-large-checkpoints/checkpoint-2000').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "converters = {'json': json.loads}\n",
    "train = pd.read_csv('../data/train_9k_valid.csv', index_col=0, converters=converters).sample(frac=1, random_state=42)\n",
    "val_set = pd.read_csv('../data/val_set_300_sb_valid.csv', index_col=0, converters=converters).sample(frac=1, random_state=42)\n",
    "manual_test = pd.read_csv('../data/manual_test_100.csv', index_col=0, converters=converters).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(json_proc.spec_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "assert train.loc[train.index[0], 'json'] == json_proc.unprocess_json(json_proc.process_json(train.loc[train.index[0], 'json']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 8766\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 45\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ads_dataset = Dataset.from_pandas(train[[\"Text\", \"json\"]])\n",
    "ads_dataset = ads_dataset.train_test_split(test_size=0.005, seed=42)\n",
    "ads_dataset = ads_dataset.flatten()\n",
    "ads_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3b0d1673014efba5db042d6a77bdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89467c95f2d0461786db86a8a233a5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4005: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [tokenizer.bos_token + text + tokenizer.eos_token for text in examples[\"Text\"]]\n",
    "    targets = [tokenizer.bos_token + json_proc.process_json(bundles) + tokenizer.eos_token for bundles in examples[\"json\"]]\n",
    "    # model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True)\n",
    "    # return model_inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "ads = ads_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ads_dataset[\"train\"].column_names\n",
    ")\n",
    "ads = ads.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricComputer:\n",
    "  def __init__(self, batch_size=8):\n",
    "    self.batch_size = batch_size\n",
    "    self.generations = []\n",
    "\n",
    "  def __call__(self, eval_preds):\n",
    "    ev = Evaluator(val_set, model=model, tokenizer=tokenizer, batch_size=self.batch_size, seq_tokens=True, json_processor=json_proc)\n",
    "    stats = ev.calc_bleu_batched()\n",
    "    self.generations.append(ev.generate_samples_batched(count=20))\n",
    "    # clear_output()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 13\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir=\"fredT5-large-checkpoints\",\n",
    "  # overwrite_output_dir=True,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  eval_steps=2500,\n",
    "  learning_rate=4e-5,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=2,\n",
    "  weight_decay=0.01,\n",
    "  save_total_limit=1,\n",
    "  num_train_epochs=n_epochs,\n",
    "  # predict_with_generate=True,\n",
    "  # generation_max_length=128,\n",
    "  lr_scheduler_type=\"cosine\",\n",
    "  group_by_length=False,\n",
    "  warmup_steps=3,\n",
    "  # fp16=True,\n",
    ")\n",
    "\n",
    "\n",
    "mc = MetricComputer(batch_size=8)\n",
    "empty_dataset = Dataset.from_dict({\"Text\": [], \"json\": []})\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=ads[\"train\"],\n",
    "  eval_dataset=ads[\"test\"],\n",
    "  # eval_dataset=empty_dataset,\n",
    "  tokenizer=tokenizer,\n",
    "  data_collator=data_collator,\n",
    "  compute_metrics=mc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12943' max='14248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12943/14248 2:46:13 < 16:45, 1.30 it/s, Epoch 11.81/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bep-sb</th>\n",
       "      <th>Bep-multi</th>\n",
       "      <th>Ta-bleu-sb</th>\n",
       "      <th>Ta-chrf-sb</th>\n",
       "      <th>Ta-chrf-multi</th>\n",
       "      <th>Eb-ind</th>\n",
       "      <th>Mb-ind</th>\n",
       "      <th>Bleu-classic</th>\n",
       "      <th>Chrf-classic</th>\n",
       "      <th>Chrf-classic-multi</th>\n",
       "      <th>Bleu Old</th>\n",
       "      <th>Failed Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.305376</td>\n",
       "      <td>0.666744</td>\n",
       "      <td>0.608176</td>\n",
       "      <td>37.365754</td>\n",
       "      <td>75.885887</td>\n",
       "      <td>74.001542</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>51.353890</td>\n",
       "      <td>72.113280</td>\n",
       "      <td>71.962766</td>\n",
       "      <td>51.353890</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.263086</td>\n",
       "      <td>0.692156</td>\n",
       "      <td>0.654763</td>\n",
       "      <td>39.265658</td>\n",
       "      <td>77.851847</td>\n",
       "      <td>76.759315</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>54.352233</td>\n",
       "      <td>74.494435</td>\n",
       "      <td>73.870299</td>\n",
       "      <td>54.352233</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.249824</td>\n",
       "      <td>0.704964</td>\n",
       "      <td>0.663203</td>\n",
       "      <td>40.805743</td>\n",
       "      <td>79.265672</td>\n",
       "      <td>77.601435</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>56.507576</td>\n",
       "      <td>75.987409</td>\n",
       "      <td>75.185944</td>\n",
       "      <td>56.507576</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.247466</td>\n",
       "      <td>0.699307</td>\n",
       "      <td>0.661789</td>\n",
       "      <td>39.337795</td>\n",
       "      <td>78.831964</td>\n",
       "      <td>77.397676</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>55.498698</td>\n",
       "      <td>75.328330</td>\n",
       "      <td>74.607341</td>\n",
       "      <td>55.498698</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.241164</td>\n",
       "      <td>0.704194</td>\n",
       "      <td>0.665725</td>\n",
       "      <td>39.674455</td>\n",
       "      <td>78.999617</td>\n",
       "      <td>77.558400</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>55.456883</td>\n",
       "      <td>75.523943</td>\n",
       "      <td>75.343507</td>\n",
       "      <td>55.456883</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T>—Ñ–æ—Ä–º–∞ –¥–ª—è –ª—å–¥–∞<P>1<C2>EUR\n",
      "<T>–±–µ–ª—ã–π –ø–∏–¥–∂–∞–∫ —Å –≤–æ–∑–¥—É—à–Ω—ã–º–∏ —à–∞—Ä–∞\n",
      "<T>–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ –∫–ª—É—ç–¥–æ/cluedo harry potter\n",
      "<T>Scrabble –¥–æ—Ä–æ–∂–Ω—ã–π<P>\n",
      "<T>–Ω–æ—É—Ç\n",
      "<T>—Ñ—É—Ç–±–æ–ª–∫–∞ Gucci<P>\n",
      "<T>–ú–∞—à–∏–Ω–∫–∏, —Å–æ—Ä—Ç–µ—Ä\n",
      "<T>–ü–ª–∞—Ç—å\n",
      "<T>braddon ¬´the lawyer‚Äôs lawyer‚Äôs lawyer‚Äôs lawyer‚Äôs lawyer‚Äôs lawyer\n",
      "<T>—Ç—Ä–∞–Ω—Å\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T>Voip-—Ç–µ–ª–µ—Ñ–æ–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π SIP –∏ H.323, Wi-Fi, Wi-Fi+, Bluetooth, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-Fi+, Wi-\n",
      "<T>–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ –∫–ª—É—ç–¥–æ/cluedo harry potter\n",
      "<T>braddon ¬´the lawyer‚Äô\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T>–¢–æ–ª—Å—Ç–æ–≤–∫–∞ —Å –∫–∞–ø—é—à–æ–Ω–æ–º\n",
      "<T>–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ –∫–ª—É—ç–¥–æ/cluedo harry potter\n",
      "<T>Rick\n",
      "<T>—Ñ—É—Ç–±–æ–ª–∫–∞ Gucci —Ä–∞–∑–º–µ—Ä –ú<P>500\n",
      "<T>–ö–Ω–∏–≥–∏, —Ä–∞—Å–∫—Ä–∞—Å–∫–∏, –∫–∞—Ä–∞–Ω–¥–∞—à–∏ –∏ —Ç–¥\n",
      "\n",
      "<T>bradd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T>–ö–æ–∂–∞–Ω–∞—è —Å—É–º–∫–∞ —Å –∫–∞—Ä–º–∞–Ω–æ–º\n",
      "<T>–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ –∫–ª—É—ç–¥–æ/cluedo harry potter\n",
      "<T>—Ñ—É—Ç–±–æ–ª–∫–∞ Gucci<P>\n",
      "\n",
      "<T>–ü–ª–∞—Ç—å–µ –Ω–æ–≤–æ–µ (–¢—É—Ä—Ü–∏—è) –†–∞–∑–º–µ—Ä 110-116 —Å–º<P>400<C1>\n",
      "<T>braddon ¬´the lawyer‚Äô\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T>–ö\n",
      "<T>Voip-—Ç–µ–ª–µ—Ñ–æ–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π SIP –∏ H.323, Wi-Fi, Bluetooth, Wi-Fi Direct, Wi-Fi Bluetooth, –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–∞—è –∫–Ω–∏–≥–∞, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ PoE, –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å –Ω–æ–º–µ—Ä–∞, –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü-—Å–≤—è–∑—å, –≥—Ä–æ–º–∫–∞—è —Å–≤—è–∑—å, –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, LCD-–¥–∏—Å–ø–ª–µ–π, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Bluetooth, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, Wi-Fi Bluetooth, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Bluetooth, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Wi-Fi Direct, –ø–æ–¥–¥–µ—Ä–∂–∫–∞\n",
      "<T>–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ –∫–ª—É—ç–¥–æ/cluedo harry potter\n",
      "<T>—Ñ—É—Ç–±–æ–ª–∫–∞ Dolce & Gabbana\n",
      "\n",
      "<T>braddon ¬´the lawyer‚Äô\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bralex/.venv/lib/python3.10/site-packages/transformers/trainer.py:1912\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1910\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bralex/.venv/lib/python3.10/site-packages/transformers/trainer.py:2294\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2289\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   2290\u001b[0m         amp\u001b[38;5;241m.\u001b[39mmaster_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer),\n\u001b[1;32m   2291\u001b[0m         args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   2292\u001b[0m     )\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2294\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2296\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2300\u001b[0m     is_accelerate_available()\n\u001b[1;32m   2301\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2302\u001b[0m ):\n\u001b[1;32m   2303\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_global_grad_norm()\n",
      "File \u001b[0;32m~/bralex/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:2158\u001b[0m, in \u001b[0;36mAccelerator.clip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   2156\u001b[0m             acc_opt\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_gradients()\n\u001b[0;32m-> 2158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bralex/.venv/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:43\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m norms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(norms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mstack(norms))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mnorm(g\u001b[38;5;241m.\u001b[39mdetach(), norm_type)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]), norm_type)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/bralex/.venv/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:43\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m norms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(norms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mstack(norms))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]), norm_type)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/bralex/.venv/lib/python3.10/site-packages/torch/functional.py:1485\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1484\u001b[0m         _dim \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)]  \u001b[38;5;66;03m# noqa: C416 TODO: rewrite as list(range(m))\u001b[39;00m\n\u001b[0;32m-> 1485\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdim\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;66;03m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;66;03m# remove the overloads where dim is an int and replace with BraodcastingList1\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;66;03m# and remove next four lines, replace _dim with dim\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fredT5-large-trained/tokenizer_config.json',\n",
       " 'fredT5-large-trained/special_tokens_map.json',\n",
       " 'fredT5-large-trained/vocab.json',\n",
       " 'fredT5-large-trained/merges.txt',\n",
       " 'fredT5-large-trained/added_tokens.json',\n",
       " 'fredT5-large-trained/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"fredT5-large-trained-sep-token\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data = pd.read_csv('../data/distill_data.csv', index_col=0)\n",
    "# distill_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev = Evaluator(distill_data)\n",
    "# output = ev.generate_samples_batched(count=20000, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
