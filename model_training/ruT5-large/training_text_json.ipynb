{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from evaluator import Evaluator\n",
    "from json_format import TextJSONProcessor\n",
    "\n",
    "json_proc = TextJSONProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_9k_valid.csv', index_col=0, converters={'json': json.loads}).sample(frac=1, random_state=42)\n",
    "val_set = pd.read_csv('../data/val_set_300_sb_valid.csv', index_col=0, converters={'json': json.loads}).sample(frac=1, random_state=42)\n",
    "manual_test = pd.read_csv('../data/manual_test_100.csv', index_col=0, converters={'json': json.loads}).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruT5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai-forever/ruT5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(json_proc.spec_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "assert train.loc[train.index[0], 'json'] == json_proc.unprocess_json(json_proc.process_json(train.loc[train.index[0], 'json']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 8634\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 177\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ads_dataset = Dataset.from_pandas(train[[\"Text\", \"json\"]])\n",
    "ads_dataset = ads_dataset.train_test_split(test_size=0.02, seed=42)\n",
    "ads_dataset = ads_dataset.flatten()\n",
    "ads_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696b5ae0b8b74dd4b1aee1b9db57594a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfe06c78ac14b2695006b8b97c00c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [text for text in examples[\"Text\"]]\n",
    "    # targets = ['' for bundles in examples[\"json\"]]\n",
    "    targets = [json_proc.process_json(bundles) for bundles in examples[\"json\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "ads = ads_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ads_dataset[\"train\"].column_names\n",
    ")\n",
    "ads = ads.flatten()\n",
    "\n",
    "# ads_test = ads_test_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     num_proc=4,\n",
    "#     remove_columns=ads_test_dataset.column_names\n",
    "# )\n",
    "# ads_test = ads_test.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class MetricComputer:\n",
    "  def __init__(self):\n",
    "    self.generations = []\n",
    "\n",
    "  def __call__(self, eval_preds):\n",
    "    ev = Evaluator(val_set, model=model, tokenizer=tokenizer, json_processor=json_proc, batch_size=24)\n",
    "    stats = ev.calc_bleu_batched()\n",
    "    self.generations.append(ev.generate_samples_batched(count=20))\n",
    "    # clear_output()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 11\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ruT5-large\",\n",
    "    # overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=750,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=24,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=n_epochs,\n",
    "    # predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    group_by_length=False,\n",
    "    warmup_steps=3,\n",
    ")\n",
    "\n",
    "mc = MetricComputer()\n",
    "empty_dataset = Dataset.from_dict({\"Text\": [], \"json\": []})\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ads[\"train\"],\n",
    "    eval_dataset=ads[\"test\"],\n",
    "    # eval_dataset=empty_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=mc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 1:02:25, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bep-sb</th>\n",
       "      <th>Bep-multi</th>\n",
       "      <th>Ta-bleu-sb</th>\n",
       "      <th>Ta-chrf-sb</th>\n",
       "      <th>Ta-chrf-multi</th>\n",
       "      <th>Eb-ind</th>\n",
       "      <th>Mb-ind</th>\n",
       "      <th>Bleu-classic</th>\n",
       "      <th>Chrf-classic</th>\n",
       "      <th>Chrf-classic-multi</th>\n",
       "      <th>Bleu Old</th>\n",
       "      <th>Failed Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.725700</td>\n",
       "      <td>0.257670</td>\n",
       "      <td>0.696885</td>\n",
       "      <td>0.633601</td>\n",
       "      <td>39.173793</td>\n",
       "      <td>77.414990</td>\n",
       "      <td>74.208251</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>52.301046</td>\n",
       "      <td>74.323402</td>\n",
       "      <td>74.128226</td>\n",
       "      <td>52.301046</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.246288</td>\n",
       "      <td>0.691719</td>\n",
       "      <td>0.651598</td>\n",
       "      <td>38.840839</td>\n",
       "      <td>77.280413</td>\n",
       "      <td>75.830699</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>50.040077</td>\n",
       "      <td>74.347446</td>\n",
       "      <td>74.792677</td>\n",
       "      <td>50.040077</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.245166</td>\n",
       "      <td>0.705087</td>\n",
       "      <td>0.659222</td>\n",
       "      <td>39.378820</td>\n",
       "      <td>77.721149</td>\n",
       "      <td>75.396857</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>50.586034</td>\n",
       "      <td>74.443197</td>\n",
       "      <td>74.527288</td>\n",
       "      <td>50.586034</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.245014</td>\n",
       "      <td>0.710756</td>\n",
       "      <td>0.670902</td>\n",
       "      <td>39.512170</td>\n",
       "      <td>78.366216</td>\n",
       "      <td>76.366890</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>52.211191</td>\n",
       "      <td>75.182280</td>\n",
       "      <td>74.759030</td>\n",
       "      <td>52.211191</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.246883</td>\n",
       "      <td>0.710776</td>\n",
       "      <td>0.673747</td>\n",
       "      <td>39.896283</td>\n",
       "      <td>78.447571</td>\n",
       "      <td>76.696014</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>51.972877</td>\n",
       "      <td>75.494117</td>\n",
       "      <td>75.293795</td>\n",
       "      <td>51.972877</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Простыня на резинке\n",
      "Стёганая сумка Reserved размер 33\n",
      "зеленый свитер\n",
      "Часы Luxury, новые в количестве 1, цена 800\n",
      "Сапоги от 40-45\n",
      "\n",
      "\n",
      "Boomerang US - Eng / Fr в количестве 1, цена\n",
      "сапоги 39р (25см)\n",
      "Фигурки агентов для игры Lodrs of Waterdeep в количестве 36, цена\n",
      "Школьная рубашка размер 140 белая и голубая в количестве 1\n",
      "\n",
      "Сапоги резиновые, размер 22, новые в количестве 19 штук\n",
      "Платье (Турция)\n",
      "Ticket to ride: The Heart of Africa\n",
      "сериал «с\n",
      "гель-лаки в количестве 12 штук, база и топ global fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion fashion\n",
      "Сапоги Демар, размер 26/27 в количестве 1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Простыня на резинке, Трикотаж 100% хлоп\n",
      "Стёганая сумка Reserved\n",
      "зеленая юбка incity в количестве 1,\n",
      "\n",
      "\n",
      "\n",
      "Машинки деревянные, щенячий патруль\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Простыня на резинке 90Х200 см в количестве 1, цена 320 (\n",
      "\n",
      "зеленая юбка incity в количестве 1, цена 25 (лари\n",
      "Часы Luxury(новые), 800 (RUB)\n",
      "Сапоги размер 40-45\n",
      "ремешки apple watch 38/41 mm, uag\n",
      "Scrabble дорожный в количестве 1, цена 700 (\n",
      "футболка Dolce Gabbana размер М в количестве 1, цена 500 (RUB\n",
      "Подсвечники в количестве 19 штук\n",
      "Костюм велюровый в количестве 1, цена\n",
      "Ticket to ride:\n",
      "белльвиль ван стоун «скетчи» в количестве 1, цена\n",
      "Сапоги Демар, размер 26/27 в количестве 1, цена 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Простыня на резинке Трикотаж 100% хлоп\n",
      "\n",
      "\n",
      "Камера Nikon 3200, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24\n",
      "футболка Dolce Gabbana размер М в количестве 1, цена 500 (RUB\n",
      "Конструктор sluban M38-B0373 в\n",
      "Платье (Турция) в количестве 1, цена 400 (\n",
      "Ticket to ride: The Heart of Africa (настольная игра, настольная игра,\n",
      "braddon «the lawyer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Простыня на резинке Трикотаж 100% хлоп\n",
      "лодочки calipso в количестве 1,\n",
      "\n",
      "\n",
      "Камера Nikon 3200, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24\n",
      "Машинки деревянные, щенячий патруль\n",
      "Костюм\n",
      "braddon «the lawyer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3960, training_loss=0.3004930245755899, metrics={'train_runtime': 3746.9228, 'train_samples_per_second': 25.347, 'train_steps_per_second': 1.057, 'total_flos': 5.0743397486592e+16, 'train_loss': 0.3004930245755899, 'epoch': 11.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1244: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> Продается: зонт в количестве 1, цена 300 (RUB)</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'продам зонт за 300 рублей'\n",
    "inputs = tokenizer(s, return_tensors='pt').to('cuda')\n",
    "out = model.generate(**inputs)\n",
    "tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'стол офисный не разбирается с тумбой и стулом 100 пафос</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ads['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Продается: стол офисный с тумбой и стулом в количестве 1, цена 100 (RUB)</s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ads['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Продается: Свёкла кормовая в количестве 1 мешок, цена 250 (RUB)</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(json_proc.process_json(train.loc[train.index[0], 'json'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruT5-large-trained-text-json/tokenizer_config.json',\n",
       " 'ruT5-large-trained-text-json/special_tokens_map.json',\n",
       " 'ruT5-large-trained-text-json/spiece.model',\n",
       " 'ruT5-large-trained-text-json/added_tokens.json',\n",
       " 'ruT5-large-trained-text-json/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"ruT5-large-trained-text-json\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data = pd.read_csv('../data/distill_data.csv', index_col=0)\n",
    "# distill_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev = Evaluator(distill_data, model, tokenizer)\n",
    "# output = ev.generate_samples_batched(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data['json'] = pd.Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data.to_csv('../data/distill_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
