{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from evaluator import Evaluator\n",
    "from json_format import SepTokenJSONProcessor\n",
    "\n",
    "json_proc = SepTokenJSONProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_9k_valid.csv', index_col=0, converters={'json': json.loads}).sample(frac=1, random_state=42)\n",
    "val_set = pd.read_csv('../data/val_set_300_sb_valid.csv', index_col=0, converters={'json': json.loads}).sample(frac=1, random_state=42)\n",
    "manual_test = pd.read_csv('../data/manual_test_100.csv', index_col=0, converters={'json': json.loads}).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruT5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai-forever/ruT5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(json_proc.spec_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "assert train.loc[train.index[0], 'json'] == json_proc.unprocess_json(json_proc.process_json(train.loc[train.index[0], 'json']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 8590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 221\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ads_dataset = Dataset.from_pandas(train[[\"Text\", \"json\"]])\n",
    "ads_dataset = ads_dataset.train_test_split(test_size=0.025, seed=42)\n",
    "ads_dataset = ads_dataset.flatten()\n",
    "ads_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57509a4acb74b22b64afd2314d5bc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0beb4c47704a228d160beee95c3d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [text for text in examples[\"Text\"]]\n",
    "    # targets = ['' for bundles in examples[\"json\"]]\n",
    "    targets = [json_proc.process_json(bundles) for bundles in examples[\"json\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "ads = ads_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ads_dataset[\"train\"].column_names\n",
    ")\n",
    "ads = ads.flatten()\n",
    "\n",
    "# ads_test = ads_test_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     num_proc=4,\n",
    "#     remove_columns=ads_test_dataset.column_names\n",
    "# )\n",
    "# ads_test = ads_test.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class MetricComputer:\n",
    "  def __init__(self):\n",
    "    self.generations = []\n",
    "\n",
    "  def __call__(self, eval_preds):\n",
    "    ev = Evaluator(val_set, model=model, tokenizer=tokenizer, json_processor=json_proc)\n",
    "    stats = ev.calc_bleu_batched()\n",
    "    self.generations.append(ev.generate_samples_batched(count=20))\n",
    "    # clear_output()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 13\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ruT5-large-sep-token\",\n",
    "    # overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    save_steps=1000,\n",
    "    num_train_epochs=n_epochs,\n",
    "    # predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    group_by_length=False,\n",
    "    warmup_steps=3,\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "mc = MetricComputer()\n",
    "empty_dataset = Dataset.from_dict({\"Text\": [], \"json\": []})\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ads[\"train\"],\n",
    "    eval_dataset=ads[\"test\"],\n",
    "    # eval_dataset=empty_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=mc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6981' max='6981' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6981/6981 1:37:58, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bep-sb</th>\n",
       "      <th>Bep-multi</th>\n",
       "      <th>Ta-bleu-sb</th>\n",
       "      <th>Ta-chrf-sb</th>\n",
       "      <th>Ta-chrf-multi</th>\n",
       "      <th>Eb-ind</th>\n",
       "      <th>Mb-ind</th>\n",
       "      <th>Bleu-classic</th>\n",
       "      <th>Chrf-classic</th>\n",
       "      <th>Chrf-classic-multi</th>\n",
       "      <th>Bleu Old</th>\n",
       "      <th>Failed Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.374192</td>\n",
       "      <td>0.684609</td>\n",
       "      <td>0.626046</td>\n",
       "      <td>38.860656</td>\n",
       "      <td>78.092665</td>\n",
       "      <td>75.328624</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>50.541831</td>\n",
       "      <td>75.717820</td>\n",
       "      <td>73.410428</td>\n",
       "      <td>50.541831</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.361724</td>\n",
       "      <td>0.695174</td>\n",
       "      <td>0.635646</td>\n",
       "      <td>37.024365</td>\n",
       "      <td>77.384247</td>\n",
       "      <td>75.104369</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>51.479422</td>\n",
       "      <td>74.875147</td>\n",
       "      <td>73.698222</td>\n",
       "      <td>51.479422</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.376220</td>\n",
       "      <td>0.700076</td>\n",
       "      <td>0.665405</td>\n",
       "      <td>39.653393</td>\n",
       "      <td>78.213808</td>\n",
       "      <td>77.129138</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>52.410314</td>\n",
       "      <td>75.239676</td>\n",
       "      <td>75.920694</td>\n",
       "      <td>52.410314</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.393244</td>\n",
       "      <td>0.719664</td>\n",
       "      <td>0.685401</td>\n",
       "      <td>40.734752</td>\n",
       "      <td>79.587859</td>\n",
       "      <td>78.720500</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>53.176079</td>\n",
       "      <td>76.848018</td>\n",
       "      <td>76.640003</td>\n",
       "      <td>53.176079</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.412297</td>\n",
       "      <td>0.720805</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>41.223969</td>\n",
       "      <td>78.898236</td>\n",
       "      <td>77.829970</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>50.513002</td>\n",
       "      <td>75.667963</td>\n",
       "      <td>76.677035</td>\n",
       "      <td>50.513002</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.417421</td>\n",
       "      <td>0.720871</td>\n",
       "      <td>0.687711</td>\n",
       "      <td>41.083173</td>\n",
       "      <td>79.182615</td>\n",
       "      <td>78.363664</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>52.179186</td>\n",
       "      <td>75.960376</td>\n",
       "      <td>76.317458</td>\n",
       "      <td>52.179186</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –∫—Ä–æ—Å—Å–æ–≤–∫–∏ –∞–¥–∏–¥–∞—Å –æ–∑–≤–∏–≥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª<P> 150<C1> 1\n",
      "<T> –ß–∞—Å—ã Luxury (–Ω–æ–≤—ã–µ), 800<C1> 1<C2> RUB\n",
      "<T> –ù–∞—Ä–¥—ã –ø–æ–¥ —Å—Ç–∞—Ä–∏–Ω—É, —Ç–µ–º–∞—Ç–∏–∫–∞ –ï–≥–∏–ø–µ—Ç, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, –¥–æ–º–∞ –∏ —Ñ–∏—à–∫–∏ –≤ –º–æ—Ä–∏–ª–∫–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, –¥–æ–º–∞ –∏ —Ñ–∏—à–∫–∏ –≤ –º–æ—Ä–∏–ª–∫–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, –¥–æ–º–∞ –∏ —Ñ–∏—à–∫–∏ –≤ –º–æ—Ä–∏–ª–∫–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, –¥–æ–º–∞ –∏ —Ñ–∏—à–∫–∏ –≤ –º–æ—Ä–∏–ª–∫–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç –≤ –∑–æ–ª–æ—Ç–æ–π –ø–∞—Ç–∏–Ω–µ, —á–µ—Ä–Ω—ã–π –º–∞—Ç\n",
      "<T> –ù–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ –ö–ª—É—ç–¥–æ/\n",
      "<T> –ö–æ—Ä\n",
      "<T> —Ñ—É—Ç–±–æ–ª–∫–∞ Gucci\n",
      "<T> –°—É–º–∫–∞ –¥–ª—è –Ω–æ—É—Ç–±—É–∫–∞ 15.6, —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç\", —Ü–≤–µ—Ç \"–º–æ–∫—Ä—ã–π\n",
      "<T> –°–∞–ø–æ–≥–∏ —Ä–µ–∑–∏–Ω–æ–≤—ã–µ, —Ä–∞–∑–º–µ—Ä 22, –Ω–æ–≤—ã–µ<P> 400<C1>\n",
      "<T> –ü–ª–∞—Ç—å–µ (\n",
      "<T> sony a6000 body with sigma 30 1.4 +600<C1> 1<C2> GEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –ü—Ä–æ—Å—Ç—ã–Ω—è –Ω–∞ —Ä–µ–∑–∏–Ω–∫–µ, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç–∞–∂, –¢—Ä–∏–∫–æ—Ç\n",
      "<T> –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ —à—Ç–∞–Ω—ã/–¥–∂–æ–≥–≥–µ—Ä—ã Befree\n",
      "<T> –ö–æ–º–ø—å—é—Ç–µ—Ä —Å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º AMD Ryzen 5 3600, –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–æ–π GIGABTE RADEON RX 580 –Ω–∞ 8 GB, –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç—å—é KINGSTON FR 16 GB (2x8GB) –∏ SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K, SSD Kingston 4K\n",
      "<T> mafia ps4<P> 10\n",
      "<T> –ö–∞–º–µ—Ä–∞ Nikon 3200, 24MP CMOS, ISO 100-6400, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP CMOS, 24MP Hy1 Sensor, ISO 100-6400, Equivalent Hi1 Sensor, 24MP Hy1 Sensor, 24MP Hy1 Sensor, 24MP Hy1 Sense, 24P Hy1 Sense, 24P Hy\n",
      "<T> Boomerang US - Eng / Fr<P>\n",
      "<T> –ö–æ–º–ø–ª–µ–∫—Ç –ø–æ—Å—Ç–µ–ª—å–Ω–æ–≥–æ –±–µ–ª—å—è –æ—Ç —Ñ–∏—Ä–º—ã '–ü–∞–Ω\n",
      "<T> –ü–ª–∞—Ç—å–µ (–¢—É—Ä—Ü–∏—è)\n",
      "<T> Ticket to ride: Germany (–æ—Ä–∏–≥–∏–Ω–∞–ª, –Ω–∞ –Ω–µ–º–µ—Ü–∫–æ–º –ø—Ä–∞–≤–∏–ª–∞)<P> 4500<C1>\n",
      "<T> braddon ¬´the lawyers\n",
      "<T> Sony A6000 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –ü—Ä–æ—Å—Ç—ã–Ω—è –Ω–∞ —Ä–µ–∑–∏–Ω–∫–µ 160—Ö200—Å–º<P> 370<C1>\n",
      "<T> –ö–æ–∂–∞–Ω–∞—è —Å—É–º–∫–∞ —Å –∫–∞—Ä–º–∞–Ω–æ–º Re\n",
      "<T> Voip-—Ç–µ–ª–µ—Ñ–æ–Ω—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323\n",
      "<T> —Ä–∞—Å—á–µ—Å–∫–∞ –¥–ª—è –ø—É—à–∏—Å—Ç–∏–∫–æ–≤\n",
      "\n",
      "<T> —Ñ—É—Ç–±–æ–ª–∫–∞ Dolce Gabbana —Ä–∞–∑–º–µ—Ä –ú<P> 500<C1>\n",
      "<T> –ú—è–≥–∫–∞—è –º–æ–∑–∞–∏–∫–∞<P> 250<C1>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –ü—Ä–æ—Å—Ç—ã–Ω—è –Ω–∞ —Ä–µ–∑–∏–Ω–∫–µ –¢—Ä–∏–∫–æ—Ç–∞–∂ 100% —Ö–ª–æ–ø–æ–∫\n",
      "<T> –ö–æ–∂–∞–Ω–∞—è —Å—É–º–∫–∞ —Å –∫–∞—Ä–º–∞–Ω–æ–º Re\n",
      "<T> Voip-—Ç–µ–ª–µ—Ñ–æ–Ω—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π SIP, H.323, WiFi, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SIP, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H.323, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ H\n",
      "<T> —Ä–∞—Å—á–µ—Å–∫–∞ –¥–ª—è –ø—É—à–∏—Å—Ç–∏–∫–æ–≤<P> 10<C1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –ü—Ä–æ—Å—Ç—ã–Ω—è –Ω–∞ —Ä–µ–∑–∏–Ω–∫–µ –¢—Ä–∏–∫–æ—Ç–∞–∂ 100% —Ö–ª–æ–ø–æ–∫\n",
      "<T> –ö–æ–∂–∞–Ω–∞—è —Å—É–º–∫–∞ —Å –∫–∞—Ä–º–∞–Ω–æ–º Re\n",
      "<T> —Ä–∞—Å—á–µ—Å–∫–∞ –¥–ª—è –ø—É—à–∏—Å—Ç–∏–∫–æ–≤\n",
      "<T>\n",
      "<T> –°–∞–ø–æ–≥–∏ —Ä–µ–∑–∏–Ω–æ–≤—ã–µ, —Ä–∞–∑–º–µ—Ä 22, –Ω–æ–≤—ã–µ<P> 400<C1>\n",
      "<T> –ü–ª–∞—Ç—å–µ (–¢—É—Ä—Ü–∏—è),\n",
      "<T> Ticket to ride: The Heart of Africa (–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞, –Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞, –Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞, –Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞, –Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞, –Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞, –Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞\n",
      "<T> braddon ¬´the lawyers secret¬ª\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –ü—Ä–æ—Å—Ç—ã–Ω—è –Ω–∞ —Ä–µ–∑–∏–Ω–∫–µ –¢—Ä–∏–∫–æ—Ç–∞–∂ 100% —Ö–ª–æ–ø–æ–∫\n",
      "<T> —Ä–∞—Å—á–µ—Å–∫–∞ –¥–ª—è –ø—É—à–∏—Å—Ç–∏–∫–æ–≤\n",
      "<T> –ü–ª–∞—Ç—å–µ (–¢—É—Ä—Ü–∏—è),\n",
      "<T> braddon ¬´the lawyer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6981, training_loss=0.27954767508862643, metrics={'train_runtime': 5881.738, 'train_samples_per_second': 18.986, 'train_steps_per_second': 1.187, 'total_flos': 5.8135359473664e+16, 'train_loss': 0.27954767508862643, 'epoch': 13.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./ruT5-large-sep-token/checkpoint-6981\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./ruT5-large-sep-token/checkpoint-6981\").to('cuda')\n",
    "\n",
    "# output_dir = \"ruT5-large-trained-sep-token\"\n",
    "# model.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –ü—Ä–æ—Å—Ç—ã–Ω—è –Ω–∞ —Ä–µ–∑–∏–Ω–∫–µ –¢—Ä–∏–∫–æ—Ç–∞–∂ 100% —Ö–ª–æ–ø–æ–∫\n",
      "<T> –ü–ª–∞—Ç—å–µ –Ω–æ–≤–æ–µ (–¢—É—Ä—Ü–∏—è), —é–±–∫–∞ –ø—ã—à–Ω–∞—è, –†–∞–∑–º–µ—Ä\n",
      "<T>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BEP-sb': 0.7163310948712148,\n",
       " 'BEP-multi': 0.686780074790732,\n",
       " 'TA-BLEU-sb': 40.70550931579893,\n",
       " 'TA-CHRF-sb': 78.82166839354579,\n",
       " 'TA-CHRF-multi': 78.37031043374178,\n",
       " 'EB-ind': 0.02,\n",
       " 'MB-ind': 0.056,\n",
       " 'BLEU-classic': 51.813201932893946,\n",
       " 'CHRF-classic': 75.55203857816018,\n",
       " 'CHRF-classic-multi': 76.57208671456245,\n",
       " 'bleu_old': 51.813201932893946,\n",
       " 'failed_ratio': 0.006}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> –∫—Ä–µ—Å–ª–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ 30<C1> 1<C2> GEL\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ev = Evaluator(manual_test, model=model, tokenizer=tokenizer, batch_size=32, json_processor=json_proc)\n",
    "output = ev.generate_samples_batched()\n",
    "df = pd.DataFrame([{'id': i, 'json': json.dumps(v, indent=4, ensure_ascii=False)} for i, v in output.items()])\n",
    "df.to_csv('manual_test_outputs_sep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data = pd.read_csv('../data/distill_data.csv', index_col=0)\n",
    "# distill_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev = Evaluator(distill_data, model, tokenizer)\n",
    "# output = ev.generate_samples_batched(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data['json'] = pd.Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill_data.to_csv('../data/distill_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
