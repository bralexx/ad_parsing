{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from evaluator import Evaluator\n",
    "from json_format import SepTokenJSONProcessor\n",
    "\n",
    "json_proc = SepTokenJSONProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_9k_valid.csv', index_col=0, converters={'json': json.loads})\n",
    "val_set = pd.read_csv('../data/val_set_300_sb_valid.csv', index_col=0, converters={'json': json.loads})\n",
    "manual_test = pd.read_csv('../data/manual_test_100.csv', index_col=0, converters={'json': json.loads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai-forever/ruT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(json_proc.spec_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "assert train.loc[train.index[0], 'json'] == json_proc.unprocess_json(json_proc.process_json(train.loc[train.index[0], 'json']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 8370\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 441\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ads_dataset = Dataset.from_pandas(train[[\"Text\", \"json\"]])\n",
    "ads_dataset = ads_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "ads_dataset = ads_dataset.flatten()\n",
    "ads_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039d444306074521a0903197e9bc7470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e300aa9f1c4642b4581653fe57b3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [text for text in examples[\"Text\"]]\n",
    "    # targets = ['' for bundles in examples[\"json\"]]\n",
    "    targets = [json_proc.process_json(bundles) for bundles in examples[\"json\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "ads = ads_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ads_dataset[\"train\"].column_names\n",
    ")\n",
    "ads = ads.flatten()\n",
    "\n",
    "# ads_test = ads_test_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     num_proc=4,\n",
    "#     remove_columns=ads_test_dataset.column_names\n",
    "# )\n",
    "# ads_test = ads_test.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricComputer:\n",
    "  def __init__(self, batch_size=8):\n",
    "    self.generations = []\n",
    "    self.batch_size=batch_size\n",
    "\n",
    "  def __call__(self, eval_preds):\n",
    "    ev = Evaluator(val_set, model=model, tokenizer=tokenizer, batch_size=self.batch_size, json_processor=json_proc)\n",
    "    stats = ev.calc_bleu_batched()\n",
    "    self.generations.append(ev.generate_samples_batched(count=20))\n",
    "    # clear_output()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ruT5-large\",\n",
    "    # overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=350,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=n_epochs,\n",
    "    # predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    group_by_length=False,\n",
    "    warmup_steps=3,\n",
    ")\n",
    "\n",
    "mc = MetricComputer(batch_size=32)\n",
    "empty_dataset = Dataset.from_dict({\"Text\": [], \"json\": []})\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ads[\"train\"],\n",
    "    eval_dataset=ads[\"test\"],\n",
    "    # eval_dataset=empty_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=mc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1965' max='1965' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1965/1965 29:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bep-sb</th>\n",
       "      <th>Bep-multi</th>\n",
       "      <th>Ta-bleu-sb</th>\n",
       "      <th>Ta-chrf-sb</th>\n",
       "      <th>Ta-chrf-multi</th>\n",
       "      <th>Eb-ind</th>\n",
       "      <th>Mb-ind</th>\n",
       "      <th>Bleu-classic</th>\n",
       "      <th>Chrf-classic</th>\n",
       "      <th>Chrf-classic-multi</th>\n",
       "      <th>Bleu Old</th>\n",
       "      <th>Failed Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572774</td>\n",
       "      <td>0.659260</td>\n",
       "      <td>0.563126</td>\n",
       "      <td>35.920429</td>\n",
       "      <td>75.419533</td>\n",
       "      <td>71.239094</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>47.662475</td>\n",
       "      <td>71.177545</td>\n",
       "      <td>66.574158</td>\n",
       "      <td>47.662475</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.317000</td>\n",
       "      <td>0.529439</td>\n",
       "      <td>0.686235</td>\n",
       "      <td>0.608175</td>\n",
       "      <td>38.609890</td>\n",
       "      <td>77.102794</td>\n",
       "      <td>73.437599</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>50.883612</td>\n",
       "      <td>73.833628</td>\n",
       "      <td>70.399028</td>\n",
       "      <td>50.883612</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.502248</td>\n",
       "      <td>0.693057</td>\n",
       "      <td>0.618103</td>\n",
       "      <td>39.171071</td>\n",
       "      <td>77.432393</td>\n",
       "      <td>73.875899</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>51.833035</td>\n",
       "      <td>74.454224</td>\n",
       "      <td>71.296968</td>\n",
       "      <td>51.833035</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.498643</td>\n",
       "      <td>0.698897</td>\n",
       "      <td>0.643622</td>\n",
       "      <td>39.299355</td>\n",
       "      <td>77.788268</td>\n",
       "      <td>75.286743</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>51.153401</td>\n",
       "      <td>74.783868</td>\n",
       "      <td>71.269562</td>\n",
       "      <td>51.153401</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.495590</td>\n",
       "      <td>0.696274</td>\n",
       "      <td>0.644112</td>\n",
       "      <td>39.500601</td>\n",
       "      <td>77.903730</td>\n",
       "      <td>75.759962</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>52.151752</td>\n",
       "      <td>74.750534</td>\n",
       "      <td>71.073191</td>\n",
       "      <td>52.151752</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> Тайлы не вы\n",
      "<T> Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра На\n",
      "<T> сань-мао «сахарные новеллы»<P> 20\n",
      "<T> настольная игра клуэдо/\n",
      "<T> Шорты\n",
      "<T> зип худи Bape размер X\n",
      "<T> Спортивные штаны/джоггеры Befree<P> 800\n",
      "<T> Одеяло верблюжья шерсть LUC<P> 500<C1>\n",
      "<T> школьная форма с платьем с коротким\n",
      "<T> Сапоги скандия, размер 30, маломерят, новые\n",
      "<T> Машинки деревянные, щенячий патруль и набор пожарного<P> 1200<C1>\n",
      "<T> Джинсы чёрные<P>\n",
      "<T> Чемодан на колесах, ручная кладь, 55х35х20, Б/У, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б\n",
      "<T> voip-телефоны с поддержкой sip, поддержка h.323, поддержка wan, lan, поддержка wan, lan, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe, поддержка poe\n",
      "<T>\n",
      "<T> Тайлы не вы\n",
      "<T> Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра Настольная игра На\n",
      "<T> сань-мао «сахарные новеллы»<P> 20\n",
      "<T> настольная игра клуэдо/\n",
      "<T> Шорты\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> Ticket to ride: The Heart of Africa (на английском) оригинал хобби ворлд<P> 2000\n",
      "<T> мурхед «восход»<P> 35\n",
      "<T>\n",
      "<T> Sigma 30 1.4 +600<C1> 1<C2> GEL\n",
      "<T> худи с\n",
      "<T> Спортивные штаны/джоггеры Bef\n",
      "<T> Самос\n",
      "<T> Брюки утеплен\n",
      "<T> Чемодан на колесах, ручная кладь, 55х35х20, Б/У, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б\n",
      "<T> платье в горошек для беременных m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/m/\n",
      "<T> Audi A4 2006 года 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, япония, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0\n",
      "<T> Платье 104 размер + болеро<P> 500\n",
      "<T>\n",
      "<T> Ticket to ride: The Heart of Africa (на английском) оригинал хобби ворлд<P> 2000\n",
      "<T> мурхед «восход»<P> 35\n",
      "<T>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> Ticket to ride: The Heart of Africa (на английском) оригинал хобби\n",
      "<T> Rick\n",
      "<T> мурхед «\n",
      "<T> Сарафан<P>\n",
      "<T> расческа для пушист\n",
      "<T> Sigma 30 1.4 +600<C1> 1<C2> GEL\n",
      "<T> Аккумулятор WORX 20V 2.0Ач<P> 1<C2> RUB\n",
      "<T> толстовка Off-W\n",
      "<T> Спортивные штаны/джоггеры\n",
      "<T> Машинки деревянные, щенячий патруль и набор пожар\n",
      "<T> Туф\n",
      "<T> лодочки calipso<P> 25\n",
      "<T> Простыня на резинке\n",
      "<T> Ticket to ride: The Heart of Africa (на английском) оригинал хобби\n",
      "<T> Rick\n",
      "<T> мурхед «\n",
      "<T> Сарафан<P>\n",
      "<T> расческа для пушист\n",
      "<T> сань-мао «сахарные новеллы»<P> 20\n",
      "<T> Костюм\n",
      "<T> Sigma 30 1.4 +600<C1> 1<C2> GEL\n",
      "<T> толстовка Off-\n",
      "<T> Коньки 39-\n",
      "<T> Простыня на резинке, хлопок, размер 140\n",
      "<T> сань-мао «сахарные новеллы»<P> 20\n",
      "<T> Костюм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<T> Костюм\n",
      "<T> Sigma 30 1.4 +600<C1> 1<C2> GEL\n",
      "<T> толстовка Off-\n",
      "<T> Простыня на резинке,\n",
      "<T> Костюм\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1965, training_loss=0.6970580744076018, metrics={'train_runtime': 1752.2279, 'train_samples_per_second': 71.652, 'train_steps_per_second': 1.121, 'total_flos': 1.911039264129024e+16, 'train_loss': 0.6970580744076018, 'epoch': 15.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruT5-base-trained-gpt-data/tokenizer_config.json',\n",
       " 'ruT5-base-trained-gpt-data/special_tokens_map.json',\n",
       " 'ruT5-base-trained-gpt-data/spiece.model',\n",
       " 'ruT5-base-trained-gpt-data/added_tokens.json',\n",
       " 'ruT5-base-trained-gpt-data/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"ruT5-base-trained-gpt-data\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
