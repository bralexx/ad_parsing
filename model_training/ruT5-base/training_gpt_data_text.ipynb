{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from evaluator import Evaluator\n",
    "from json_format import TextJSONProcessor\n",
    "\n",
    "json_proc = TextJSONProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_9k_valid.csv', index_col=0, converters={'json': json.loads})\n",
    "val_set = pd.read_csv('../data/val_set_300_sb_valid.csv', index_col=0, converters={'json': json.loads})\n",
    "manual_test = pd.read_csv('../data/manual_test_100.csv', index_col=0, converters={'json': json.loads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai-forever/ruT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(json_proc.spec_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "assert train.loc[train.index[0], 'json'] == json_proc.unprocess_json(json_proc.process_json(train.loc[train.index[0], 'json']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 8370\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'json', '__index_level_0__'],\n",
       "        num_rows: 441\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ads_dataset = Dataset.from_pandas(train[[\"Text\", \"json\"]])\n",
    "ads_dataset = ads_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "ads_dataset = ads_dataset.flatten()\n",
    "ads_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1164b8f5e50e48b885dee19b7257bc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cfc254d4264c1c8223439e83cc8729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [text for text in examples[\"Text\"]]\n",
    "    # targets = ['' for bundles in examples[\"json\"]]\n",
    "    targets = [json_proc.process_json(bundles) for bundles in examples[\"json\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "ads = ads_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ads_dataset[\"train\"].column_names\n",
    ")\n",
    "ads = ads.flatten()\n",
    "\n",
    "# ads_test = ads_test_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     num_proc=4,\n",
    "#     remove_columns=ads_test_dataset.column_names\n",
    "# )\n",
    "# ads_test = ads_test.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricComputer:\n",
    "  def __init__(self, batch_size=8):\n",
    "    self.generations = []\n",
    "    self.batch_size=batch_size\n",
    "\n",
    "  def __call__(self, eval_preds):\n",
    "    ev = Evaluator(val_set, model=model, tokenizer=tokenizer, batch_size=self.batch_size, json_processor=json_proc)\n",
    "    stats = ev.calc_bleu_batched()\n",
    "    self.generations.append(ev.generate_samples_batched(count=20))\n",
    "    # clear_output()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ruT5-large\",\n",
    "    # overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=350,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=n_epochs,\n",
    "    # predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    group_by_length=False,\n",
    "    warmup_steps=3,\n",
    ")\n",
    "\n",
    "mc = MetricComputer(batch_size=32)\n",
    "empty_dataset = Dataset.from_dict({\"Text\": [], \"json\": []})\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ads[\"train\"],\n",
    "    eval_dataset=ads[\"test\"],\n",
    "    # eval_dataset=empty_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=mc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1965' max='1965' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1965/1965 31:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bep-sb</th>\n",
       "      <th>Bep-multi</th>\n",
       "      <th>Ta-bleu-sb</th>\n",
       "      <th>Ta-chrf-sb</th>\n",
       "      <th>Ta-chrf-multi</th>\n",
       "      <th>Eb-ind</th>\n",
       "      <th>Mb-ind</th>\n",
       "      <th>Bleu-classic</th>\n",
       "      <th>Chrf-classic</th>\n",
       "      <th>Chrf-classic-multi</th>\n",
       "      <th>Bleu Old</th>\n",
       "      <th>Failed Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.517620</td>\n",
       "      <td>0.640803</td>\n",
       "      <td>0.549075</td>\n",
       "      <td>35.870830</td>\n",
       "      <td>74.111133</td>\n",
       "      <td>69.130526</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>46.824849</td>\n",
       "      <td>69.697365</td>\n",
       "      <td>65.484622</td>\n",
       "      <td>46.824849</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.044800</td>\n",
       "      <td>0.479050</td>\n",
       "      <td>0.680357</td>\n",
       "      <td>0.609939</td>\n",
       "      <td>39.765578</td>\n",
       "      <td>77.201041</td>\n",
       "      <td>74.779221</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>48.311692</td>\n",
       "      <td>73.203884</td>\n",
       "      <td>71.970504</td>\n",
       "      <td>48.311692</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>0.456884</td>\n",
       "      <td>0.690033</td>\n",
       "      <td>0.635098</td>\n",
       "      <td>40.201262</td>\n",
       "      <td>77.263306</td>\n",
       "      <td>75.564854</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>51.613084</td>\n",
       "      <td>74.150365</td>\n",
       "      <td>72.951086</td>\n",
       "      <td>51.613084</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>0.448651</td>\n",
       "      <td>0.703422</td>\n",
       "      <td>0.647954</td>\n",
       "      <td>40.500680</td>\n",
       "      <td>78.261840</td>\n",
       "      <td>76.860553</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>52.152377</td>\n",
       "      <td>75.036528</td>\n",
       "      <td>73.795777</td>\n",
       "      <td>52.152377</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.442184</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.641601</td>\n",
       "      <td>39.080469</td>\n",
       "      <td>77.589081</td>\n",
       "      <td>76.026903</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>50.503031</td>\n",
       "      <td>74.441197</td>\n",
       "      <td>73.389587</td>\n",
       "      <td>50.503031</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrabble дорожный в количестве 1, цена 700 (RUB\n",
      "умберто эко «растительная память» в количестве 1, цена 25 (\n",
      "Пла\n",
      "Шорт\n",
      "чехлы для iphone 7. 3 силиконовых, один пластиковый, один пластиковый\n",
      "sigma 30 1.4 +600 gel с Sigma 30 1.4 +600 gel с Sigma 30 1.4 +600 gel с Sigma 30 1.4 +600 gel с Sigma 30 1.4 +600 gel с Sigma 30 1.4 +600 gel с Sigma 30 1.4 + 600 gel с Sigma 30 1.4 + 600 gel с Sigma 30 1.4 + 600 gel с Sigma 30 1.4 + 600 gel с Sigma 30 1.4 + 150 gel с Sigma 30 1.4 + 150\n",
      "худи с лампасами размер L в количестве 1\n",
      "Одеяло верблюжья шерсть LUC в количестве\n",
      "платье с коротким рукавом в\n",
      "Шапка-шлем, 54 размер в количестве 1, цена\n",
      "Джин\n",
      "Пеги на велик b\n",
      "монитор onn 24\" model: onn 24\" model: onn 24\" model: onn 24\" model: onn 24\" model: onn 24\" model: onn\n",
      "штаны на клепках ellesse 5/5 s-m в количестве 1, цена 65 (GEL\n",
      "игрушка ручной работы пикачу, рост до головы 22 см, рост до головы 22 см, рост до головы 22 см, до ушей 27 см, до ушей 27 см, одежда съёмная в количестве 1, цена 35 (ла\n",
      "майка karl kani размер м в количестве 1, цена:30 (GEL)\n",
      "nintendo switch, полный комплект, полный комплект, джойстики, экран, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, джойстики, экран, защитное стекло в количестве 1\n",
      "Платье 104 размер + болеро в количестве 1, цена 500 (RU\n",
      "cisco 891w router в\n",
      "Простыня на резинке в количестве 1\n",
      "Scrabble дорожный в количестве 1, цена 700 (RUB\n",
      "умберто эко «растительная память» в количестве 1, цена 25 (\n",
      "Пла\n",
      "Шорт\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "морд\n",
      "настольная игра клуэдо/cluedo harry po\n",
      "Sigma 30 1.4 + 600 (GEL)\n",
      "худи с лампас\n",
      "Подсвечники, 19 штук,\n",
      "Чемодан на колесах, ручная кладь, 55х35х20, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у, б/у,\n",
      "Audi A4 2006 года 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, 2.0l автомат, япония, импортная, комплектация, ксенон, електро сиденья, с регулировками, с регулировками, 7 динамиков, сабвуфер\n",
      "майка karl kani в количестве 1, цена:30 (GEL)\n",
      "зеленые классические брюки в количестве 1,\n",
      "Простыня на резинке, ткань Трикотаж, ткань Трикот\n",
      "морд\n",
      "настольная игра клуэдо/cluedo harry po\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "braddon «the law\n",
      "Платье (Турция) в количестве 1, цена 400 (RUB\n",
      "расческа\n",
      "худи с лампас\n",
      "майка karl kani в количестве 1, цена:30 (GEL)\n",
      "Простыня на резинке, 100% хлопок в количестве 1, цена 300 (\n",
      "braddon «the law\n",
      "Платье (Турция) в количестве 1, цена 400 (RUB\n",
      "расческа\n",
      "braddon «the lawyers secret\n",
      "расчес\n",
      "худи с лампасами Off-W\n",
      "Просты\n",
      "braddon «the lawyers secret\n",
      "расчес\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/bralex/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Джинсы в количестве 1, цена 400\n",
      "расчес\n",
      "Sigma 30 1.4 +600 (GEL)\n",
      "Простыня на резинке 140х200см в количестве 1,\n",
      "\n",
      "Костюм велюровый в\n",
      "расчес\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1965, training_loss=0.5892136280166587, metrics={'train_runtime': 1876.6636, 'train_samples_per_second': 66.901, 'train_steps_per_second': 1.047, 'total_flos': 1.911039264129024e+16, 'train_loss': 0.5892136280166587, 'epoch': 15.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruT5-base-trained-gpt-data/tokenizer_config.json',\n",
       " 'ruT5-base-trained-gpt-data/special_tokens_map.json',\n",
       " 'ruT5-base-trained-gpt-data/spiece.model',\n",
       " 'ruT5-base-trained-gpt-data/added_tokens.json',\n",
       " 'ruT5-base-trained-gpt-data/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"ruT5-base-trained-gpt-data\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
